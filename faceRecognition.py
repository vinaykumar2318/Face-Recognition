# -*- coding: utf-8 -*-
"""face_recognition.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fCVS87RY16ql-hTSjf8TEx2vFvrFt-pJ

# Imports
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import cv2
import math
from skimage.feature import hog

import warnings
warnings.filterwarnings('ignore')

"""# Fetching and analysing the data
Minimum number of faces per person selected = 70

Number of labels = 7

Number of images = 1288
"""

from sklearn.datasets import fetch_lfw_people

# Download and load the LFW dataset
lfw_dataset = fetch_lfw_people(min_faces_per_person=70, resize=0.4)

# Extract data and target labels
X = lfw_dataset.images
y = lfw_dataset.target
target_names = lfw_dataset.target_names

# Print information about the dataset
print("Number of images:", X.shape[0])
print("Image size:", X.shape[1:])
print("Number of unique classes:", len(target_names))
print("Target class names:", target_names)
num_samples, num_features = lfw_dataset.data.shape
num_classes = len(target_names)

""" Sample images"""

num_samples_to_display = 5
random_indices = np.random.choice(num_samples, num_samples_to_display, replace=False)

plt.figure(figsize=(10, 4))
for i, index in enumerate(random_indices, 1):
    plt.subplot(1, num_samples_to_display, i)
    plt.imshow(X[index].reshape((50, 37)), cmap='gray')
    plt.title(target_names[y[index]])
    plt.axis('off')
plt.show()

"""Distribution of classes"""

class_counts = np.bincount(y)
plt.bar(range(num_classes), class_counts)
plt.xlabel('Class Index')
plt.ylabel('Number of Samples')
plt.title('Distribution of Classes')
plt.xticks(range(num_classes), target_names, rotation=90)
plt.show()

"""Analysing how each image data looks like"""

print('shape of each image data: ',lfw_dataset.images[0].shape)
print(lfw_dataset.images[0])
plt.axis("off")
plt.imshow(lfw_dataset.images[0], cmap='gray')

"""Reshaping the data into single array of 1850 (50 * 37) features"""

print('shape of each image data: ',lfw_dataset.data[0].shape)
print(lfw_dataset.data[0])

"""# Implementing Different Feature Extraction Techniques from Scratch


*   Linear Binary Pattern [LBP]
*   Histogram of Oriented Gradients [HoG]
*   Convolutional Neural Networks [CNN]

##Linear Binary Pattern

From Scratch implementation
"""

def lbp_features(image):
  lbp_image = np.ones([50,37])
  for y in range(1,image.shape[0]-1):
    for x in range(1,image.shape[1]-1):
      l = [*list(image[y-1][x-1:x+2]),image[y][x+1],*list(image[y+1][x+1:x-1:-1]),image[y+1][x-1],image[y][x-1]]
      mwl= [2**i if image[y][x] >= l[i] else 0 for i in range(len(l))]
      lbp_image[y][x] = sum(mwl)
  return lbp_image

"""Original Image"""

plt.axis("off")
plt.title('Original')
plt.imshow(lfw_dataset.images[163],cmap='gray')

"""LBP Feature Extracted Image"""

a = lbp_features(lfw_dataset.images[163])
plt.axis("off")
plt.imshow(a,cmap='gray')

"""LBP using sklearn local_binary_pattern function"""

from skimage.feature import local_binary_pattern
radius = 1
num_points = 8 * radius
lbp_image = local_binary_pattern(lfw_dataset.images[163], num_points, radius, method='uniform')
plt.axis("off")
plt.imshow(lbp_image.astype(np.uint8), cmap= 'gray')

"""## Histogram of Oriented Gradients

**Resizing Image to 64 X 128 size**
"""

img = cv2.resize(lfw_dataset.images[163], (64, 128))
plt.axis("off")
plt.imshow(img, cmap='gray')

"""**Vertical Gradient Detection**"""

def img_gradient_ver(image):
  lbp_image = np.ones(image.shape)
  for y in range(0,image.shape[0]):
    for x in range(1,image.shape[1]-1):
      lbp_image[y][x] = image[y][x+1]-image[y][x-1]
  return lbp_image

a = img_gradient_ver(img)
plt.axis("off")
plt.imshow(a,cmap='gray')

"""**Horizontal Gradient Detection**"""

def img_gradient_horr(image):
  lbp_image = np.ones(image.shape)
  for y in range(1,image.shape[0]-1):
    for x in range(0,image.shape[1]):
      lbp_image[y][x] = image[y+1][x]-image[y-1][x]
  return lbp_image

b = img_gradient_horr(img)
plt.axis("off")
plt.imshow(b,cmap='gray')

"""**Adding both vertical and horizontal gradients**"""

plt.axis("off")
plt.imshow(a+b,cmap='gray')

"""**Gradient and Angle of image**"""

mag = []
theta = []
for i in range(128):
  magnitudeArray = []
  angleArray = []
  for j in range(64):

    if j-1 <= 0 or j+1 >= 64:
      if j-1 <= 0:
        Gx = img[i][j+1] - 0
      elif j + 1 >= len(img[0]):
        Gx = 0 - img[i][j-1]
    else:
      Gx = img[i][j+1] - img[i][j-1]

    if i-1 <= 0 or i+1 >= 128:
      if i-1 <= 0:
        Gy = 0 - img[i+1][j]
      elif i +1 >= 128:
        Gy = img[i-1][j] - 0
    else:
      Gy = img[i-1][j] - img[i+1][j]

    magnitude = math.sqrt(pow(Gx, 2) + pow(Gy, 2))     # Calculating magnitude
    magnitudeArray.append(round(magnitude, 9))

    if Gx == 0:     # Calculating angle
      angle = math.degrees(0.0)
    else:
      angle = math.degrees(abs(math.atan(Gy / Gx)))
    angleArray.append(round(angle, 9))
  mag.append(magnitudeArray)
  theta.append(angleArray)

"""**Represetation of magnitude of gradient of image**"""

plt.imshow(mag, cmap="gray")
plt.axis("off")
plt.title('Magnitudes')
plt.show()

"""**Representation of angle of image**"""

plt.imshow(theta, cmap="gray")
plt.axis("off")
plt.title('Angles')
plt.show()

"""**Final Histogram of Oriented Gradients Image**"""

_ , hog_image = hog(img, orientations=8, pixels_per_cell=(8, 8),
                             cells_per_block=(2, 2), visualize=True)
plt.axis('off')
plt.title('HoG')
plt.imshow(hog_image, cmap='gray')

"""## Convolutional Layers

Convolution function from scratch
"""

def convolutional_features(image, kernel):
    output = np.zeros((image.shape[0] - kernel.shape[0] + 1, image.shape[1] - kernel.shape[1] + 1))
    for i in range(output.shape[0]):
      for j in range(output.shape[1]):
        output[i, j] = np.multiply(image[i:i+kernel.shape[0],j:j+kernel.shape[1]],kernel).sum()
    return output

"""3 different types of kernels"""

kernel_ver = np.array([[-1, 0, 1],
                   [-2,0,2],
                   [-1,0,1]])

kernel_hor = np.array([[-1, -2, -1],
                   [0,0,0],
                   [1,2,1]])

kernel_gabor = np.array([[-0.2324, -0.268, -0.2324],
                   [0.8673,1,0.8673],
                   [-0.2324,-0.268,-0.2324]])

"""Verrtical kernel for edge detection"""

d = convolutional_features(lfw_dataset.images[163], kernel_ver)
plt.axis('off')
plt.title('Vertical Edges')
plt.imshow(d, cmap='gray')

"""Horizontal kernel for edge detection"""

e = convolutional_features(lfw_dataset.images[163], kernel_hor)
plt.title('Horizontal Edges')
plt.axis('off')
plt.imshow(e, cmap='gray')

"""Gabor Filter Kernel"""

f = convolutional_features(lfw_dataset.images[163], kernel_gabor)
plt.title('Gabor')
plt.axis('off')
plt.imshow(f, cmap='gray')

"""Using all 3 at the same time"""

plt.axis('off')
plt.imshow(d + e + f, cmap ='gray')

"""# Classification
Classifying the images with different classifiers:

*   SVM
*   KNN
*   Decision Tree




"""

from sklearn.metrics import classification_report, accuracy_score, ConfusionMatrixDisplay
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.decomposition import PCA
from sklearn.model_selection import RandomizedSearchCV, train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC

"""Trying PCA"""

X = lfw_dataset.data
y = lfw_dataset.target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=69)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train) #scaling train and test data
X_test = scaler.transform(X_test)

pca = PCA(n_components = 10)
pca.fit(X_train)
print(pca.explained_variance_ratio_)

"""#Results with LBP"""

X_train = np.reshape(X_train, (X_train.shape[0], 50, 37))
X_test = np.reshape(X_test, (X_test.shape[0], 50, 37))

X_train_lbp = [lbp_features(x) for x in X_train]
X_test_lbp = [lbp_features(x) for x in X_test]

X_train_lbp = np.array(X_train_lbp)
X_test_lbp = np.array(X_test_lbp)

X_train_lbp = X_train_lbp.reshape((X_train.shape[0], 50*37))
X_test_lbp = X_test_lbp.reshape((X_test.shape[0], 50*37))

"""SVM"""

svm_lbp = SVC(kernel='rbf', decision_function_shape='ovo' )
svm_lbp.fit(X_train_lbp, y_train)

lbp_predictions = svm_lbp.predict(X_test_lbp)
print(classification_report(y_test, lbp_predictions, target_names = target_names))
ConfusionMatrixDisplay.from_estimator(svm_lbp, X_test_lbp, y_test, display_labels=target_names, xticks_rotation="vertical")
plt.tight_layout()
plt.show()

"""KNN"""

knn_lbp = KNeighborsClassifier(n_neighbors = 5)
knn_lbp.fit(X_train_lbp, y_train)

lbp_predictions = knn_lbp.predict(X_test_lbp)
print(classification_report(y_test, lbp_predictions, target_names = target_names))
ConfusionMatrixDisplay.from_estimator(knn_lbp, X_test_lbp, y_test, display_labels=target_names, xticks_rotation="vertical")
plt.tight_layout()
plt.show()

"""Decision Tree"""

tree_lbp = DecisionTreeClassifier()
tree_lbp.fit(X_train_lbp, y_train)

lbp_predictions = tree_lbp.predict(X_test_lbp)
print(classification_report(y_test, lbp_predictions, target_names = target_names))
ConfusionMatrixDisplay.from_estimator(tree_lbp, X_test_lbp, y_test, display_labels=target_names, xticks_rotation="vertical")
plt.tight_layout()
plt.show()

"""# Results with HoG"""

X_train_hog = [hog_image for _ , hog_image in [hog(x, orientations=8, pixels_per_cell=(8, 8),cells_per_block=(2, 2), visualize=True) for x in X_train]]
X_test_hog = [hog_image for _ , hog_image in [hog(x, orientations=8, pixels_per_cell=(8, 8),cells_per_block=(2, 2), visualize=True) for x in X_test]]

X_train_hog = np.array(X_train_hog)
X_test_hog = np.array(X_test_hog)

X_train_hog = X_train_hog.reshape((X_train.shape[0], 50*37))
X_test_hog = X_test_hog.reshape((X_test.shape[0], 50*37))

"""SVM"""

svm_hog = SVC(kernel = 'rbf', decision_function_shape='ovo')
svm_hog.fit(X_train_hog, y_train)

hog_predictions = svm_hog.predict(X_test_hog)
print(classification_report(y_test, hog_predictions, target_names = target_names))
ConfusionMatrixDisplay.from_estimator(svm_hog, X_test_hog, y_test, display_labels=target_names, xticks_rotation="vertical")
plt.tight_layout()
plt.show()

"""KNN"""

knn_hog = KNeighborsClassifier(n_neighbors = 5)
knn_hog.fit(X_train_hog, y_train)

hog_predictions = knn_hog.predict(X_test_hog)
print(classification_report(y_test, hog_predictions, target_names = target_names))
ConfusionMatrixDisplay.from_estimator(knn_hog, X_test_hog, y_test, display_labels=target_names, xticks_rotation="vertical")
plt.tight_layout()
plt.show()

"""Decision Tree"""

tree_hog = DecisionTreeClassifier()
tree_hog.fit(X_train_hog, y_train)

hog_predictions = tree_hog.predict(X_test_hog)
print(classification_report(y_test, hog_predictions, target_names = target_names))
ConfusionMatrixDisplay.from_estimator(tree_hog, X_test_hog, y_test, display_labels=target_names, xticks_rotation="vertical")
plt.tight_layout()
plt.show()

"""# Results with CNN"""

from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from keras.utils import to_categorical
import keras

model = Sequential()

model.add(Conv2D(1, (3, 3), activation='relu', input_shape=(50, 37, 1)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(1, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(len(np.unique(y)), activation='softmax'))

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])


y_categorical = to_categorical(y_train, num_classes=len(np.unique(y)))
model.fit(X_train, y_categorical, epochs=50, batch_size=32, validation_split=0.2)

def cnn_activations(input, layer, filters):
  conv_layer = model.get_layer(layer)  #put name of the actual convolutional layer, based on the error message
  conv_model = keras.Model(inputs=model.inputs, outputs=conv_layer.output)

  activations = conv_model.predict(input)
  activations = np.squeeze(activations, axis=0)
  activation_map = activations[:, :, filters - 1]

  return activation_map

image = X_test[0]
plt.imshow(image, cmap='gray')
image = np.expand_dims(image, axis=0)
image = np.expand_dims(image, axis=-1)
print(image.shape)

plt.imshow(cnn_activations(image, 'conv2d_2', 1), cmap='gray')

X_train_cnn = [cnn_activations(np.expand_dims(np.expand_dims(x, axis=0), axis=-1), 'conv2d_2', 1) for x in X_train]
X_test_cnn = [cnn_activations(np.expand_dims(np.expand_dims(x, axis=0), axis=-1), 'conv2d_2', 1) for x in X_test]

X_train_cnn = np.array(X_train_cnn)
X_test_cnn = np.array(X_test_cnn)

X_train_cnn = X_train_cnn.reshape((X_train.shape[0], 48*35))
X_test_cnn = X_test_cnn.reshape((X_test.shape[0], 48*35))

"""SVM"""

svm_cnn = SVC(kernel = 'rbf', decision_function_shape='ovo')
svm_cnn.fit(X_train_cnn, y_train)

cnn_predictions = svm_cnn.predict(X_test_cnn)
print(classification_report(y_test, cnn_predictions, target_names = target_names))
ConfusionMatrixDisplay.from_estimator(svm_cnn, X_test_cnn, y_test, display_labels=target_names, xticks_rotation="vertical")
plt.tight_layout()
plt.show()

"""KNN"""

knn_cnn = KNeighborsClassifier(n_neighbors = 5)
knn_cnn.fit(X_train_cnn, y_train)

cnn_predictions = knn_cnn.predict(X_test_cnn)
print(classification_report(y_test, cnn_predictions, target_names = target_names))
ConfusionMatrixDisplay.from_estimator(knn_cnn, X_test_cnn, y_test, display_labels=target_names, xticks_rotation="vertical")
plt.tight_layout()
plt.show()

"""Decision Tree"""

tree_cnn = DecisionTreeClassifier()
tree_cnn.fit(X_train_cnn, y_train)

cnn_predictions = tree_cnn.predict(X_test_cnn)
print(classification_report(y_test, cnn_predictions, target_names = target_names))
ConfusionMatrixDisplay.from_estimator(tree_cnn, X_test_cnn, y_test, display_labels=target_names, xticks_rotation="vertical")
plt.tight_layout()
plt.show()